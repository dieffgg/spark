{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-datalake-store\n",
      "  Using cached azure_datalake_store-0.0.48-py2.py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from azure-datalake-store) (2.23.0)\n",
      "Collecting adal>=0.4.2\n",
      "  Downloading adal-1.2.3-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 763 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cffi in /opt/conda/lib/python3.7/site-packages (from azure-datalake-store) (1.14.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->azure-datalake-store) (1.25.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->azure-datalake-store) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->azure-datalake-store) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->azure-datalake-store) (2019.11.28)\n",
      "Requirement already satisfied: PyJWT>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from adal>=0.4.2->azure-datalake-store) (1.7.1)\n",
      "Requirement already satisfied: cryptography>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from adal>=0.4.2->azure-datalake-store) (2.8)\n",
      "Requirement already satisfied: python-dateutil>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from adal>=0.4.2->azure-datalake-store) (2.8.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi->azure-datalake-store) (2.20)\n",
      "Requirement already satisfied: six>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from cryptography>=1.1.0->adal>=0.4.2->azure-datalake-store) (1.14.0)\n",
      "Installing collected packages: adal, azure-datalake-store\n",
      "Successfully installed adal-1.2.3 azure-datalake-store-0.0.48\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-datalake-store \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.datalake.store import core, lib, multithread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "            .master(\"local[8]\") \\\n",
    "            .appName(\"airflow_app\") \\\n",
    "            .config('spark.executor.memory', '16g') \\\n",
    "            .config('spark.driver.memory', '16g') \\\n",
    "            .config('spark.sql.execution.pandas.respectSessionTimeZone', False) \\\n",
    "            .config(\"spark.driver.maxResultSize\", \"2048MB\") \\\n",
    "            .config(\"spark.port.maxRetries\", \"100\") \\\n",
    "            .config(\"spark.sql.execution.arrow.enabled\", \"true\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code BZ5N36ZK2 to authenticate.\n"
     ]
    }
   ],
   "source": [
    "adlCreds = lib.auth(url_suffix='raizenprd01', resource='https://datalake.azure.net/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"fs.adl.oauth2.access.token.provider.type\", \"RefreshToken\")\n",
    "spark.conf.set(\"fs.adl.oauth2.client.id\", adlCreds.token['client'])\n",
    "spark.conf.set(\"fs.adl.oauth2.refresh.token\", adlCreds.token['refreshToken'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType,StructField, StructType  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = pd.date_range(start='1-1-2012', end='31-12-2019').to_frame(index=False,name='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               Date|\n",
      "+-------------------+\n",
      "|2012-01-01 00:00:00|\n",
      "|2012-01-02 00:00:00|\n",
      "|2012-01-03 00:00:00|\n",
      "|2012-01-04 00:00:00|\n",
      "|2012-01-05 00:00:00|\n",
      "|2012-01-06 00:00:00|\n",
      "|2012-01-07 00:00:00|\n",
      "|2012-01-08 00:00:00|\n",
      "|2012-01-09 00:00:00|\n",
      "|2012-01-10 00:00:00|\n",
      "|2012-01-11 00:00:00|\n",
      "|2012-01-12 00:00:00|\n",
      "|2012-01-13 00:00:00|\n",
      "|2012-01-14 00:00:00|\n",
      "|2012-01-15 00:00:00|\n",
      "|2012-01-16 00:00:00|\n",
      "|2012-01-17 00:00:00|\n",
      "|2012-01-18 00:00:00|\n",
      "|2012-01-19 00:00:00|\n",
      "|2012-01-20 00:00:00|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
